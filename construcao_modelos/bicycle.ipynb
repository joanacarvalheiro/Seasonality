{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import plotly.express as px\n",
    "from sqlalchemy import create_engine\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import MSTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexão ao PostgreSQl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = \"avnadmin\"\n",
    "# password = \"AVNS_9fZb3BkX9qGXxKpxsrZ\"\n",
    "# host = \"postgresql-iscac.f.aivencloud.com\"\n",
    "# port = \"25674\"\n",
    "# bucket = \"Seasonality\"\n",
    "\n",
    "# # URL de conexão com PostgreSQL\n",
    "# engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{bucket}')\n",
    "\n",
    "# #Nome da tabela \n",
    "# meteorology ='bicycle_counter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar dados do PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 22632 entries, 2021-08-01 00:00:00 to 2024-02-29 23:00:00\n",
      "Data columns (total 62 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   direction_2   22632 non-null  int32\n",
      " 1   count_2       22632 non-null  int32\n",
      " 2   direction_3   22632 non-null  int32\n",
      " 3   count_3       22632 non-null  int32\n",
      " 4   direction_4   22632 non-null  int32\n",
      " 5   count_4       22632 non-null  int32\n",
      " 6   direction_5   22632 non-null  int32\n",
      " 7   count_5       22632 non-null  int32\n",
      " 8   direction_6   22632 non-null  int32\n",
      " 9   count_6       22632 non-null  int32\n",
      " 10  direction_7   22632 non-null  int32\n",
      " 11  count_7       22632 non-null  int32\n",
      " 12  direction_8   22632 non-null  int32\n",
      " 13  count_8       22632 non-null  int32\n",
      " 14  direction_9   22632 non-null  int32\n",
      " 15  count_9       22632 non-null  int32\n",
      " 16  direction_10  22632 non-null  int32\n",
      " 17  count_10      22632 non-null  int32\n",
      " 18  direction_11  22632 non-null  int32\n",
      " 19  count_11      22632 non-null  int32\n",
      " 20  direction_12  22632 non-null  int32\n",
      " 21  count_12      22632 non-null  int32\n",
      " 22  direction_13  22632 non-null  int32\n",
      " 23  count_13      22632 non-null  int32\n",
      " 24  direction_14  22632 non-null  int32\n",
      " 25  count_14      22632 non-null  int32\n",
      " 26  direction_15  22632 non-null  int32\n",
      " 27  count_15      22632 non-null  int32\n",
      " 28  direction_16  22632 non-null  int32\n",
      " 29  count_16      22632 non-null  int32\n",
      " 30  direction_17  22632 non-null  int32\n",
      " 31  count_17      22632 non-null  int32\n",
      " 32  direction_19  22632 non-null  int32\n",
      " 33  count_19      22632 non-null  int32\n",
      " 34  direction_20  22632 non-null  int32\n",
      " 35  count_20      22632 non-null  int32\n",
      " 36  direction_21  22632 non-null  int32\n",
      " 37  count_21      22632 non-null  int32\n",
      " 38  direction_22  22632 non-null  int32\n",
      " 39  count_22      22632 non-null  int32\n",
      " 40  direction_24  22632 non-null  int32\n",
      " 41  count_24      22632 non-null  int32\n",
      " 42  direction_25  22632 non-null  int32\n",
      " 43  count_25      22632 non-null  int32\n",
      " 44  direction_26  22632 non-null  int32\n",
      " 45  count_26      22632 non-null  int32\n",
      " 46  direction_28  22632 non-null  int32\n",
      " 47  count_28      22632 non-null  int32\n",
      " 48  direction_29  22632 non-null  int32\n",
      " 49  count_29      22632 non-null  int32\n",
      " 50  direction_30  22632 non-null  int32\n",
      " 51  count_30      22632 non-null  int32\n",
      " 52  direction_31  22632 non-null  int32\n",
      " 53  count_31      22632 non-null  int32\n",
      " 54  direction_32  22632 non-null  int32\n",
      " 55  count_32      22632 non-null  int32\n",
      " 56  direction_33  22632 non-null  int32\n",
      " 57  count_33      22632 non-null  int32\n",
      " 58  direction_34  22632 non-null  int32\n",
      " 59  count_34      22632 non-null  int32\n",
      " 60  direction_35  22632 non-null  int32\n",
      " 61  count_35      22632 non-null  int32\n",
      "dtypes: int32(62)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Como a Api ainda não esta a funcionar, vou importar os dados de um csv\n",
    "df = pd.read_csv('../all_bike_counts.csv', parse_dates=['detected'], dtype='int32')\n",
    "df = df.set_index('detected')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31 entries, 0 to 30\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   locationId         31 non-null     int64  \n",
      " 1   tenantIdentifier   31 non-null     object \n",
      " 2   name               31 non-null     object \n",
      " 3   cp7                31 non-null     object \n",
      " 4   freguesia          31 non-null     object \n",
      " 5   directionPositive  0 non-null      float64\n",
      " 6   directionNegative  0 non-null      float64\n",
      " 7   latitude           31 non-null     float64\n",
      " 8   longitude          31 non-null     float64\n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 2.3+ KB\n",
      "\n",
      "                     direction_2  count_2  direction_3  count_3  direction_4  \\\n",
      "detected                                                                       \n",
      "2021-08-01 00:00:00            0        0            1        1            0   \n",
      "2021-08-01 01:00:00            3        3            0        2            0   \n",
      "\n",
      "                     count_4  direction_5  count_5  direction_6  count_6  ...  \\\n",
      "detected                                                                  ...   \n",
      "2021-08-01 00:00:00        0            0        0            6        7  ...   \n",
      "2021-08-01 01:00:00        0            0        0            0        4  ...   \n",
      "\n",
      "                     direction_31  count_31  direction_32  count_32  \\\n",
      "detected                                                              \n",
      "2021-08-01 00:00:00             1         1             3         7   \n",
      "2021-08-01 01:00:00             1         1             1         7   \n",
      "\n",
      "                     direction_33  count_33  direction_34  count_34  \\\n",
      "detected                                                              \n",
      "2021-08-01 00:00:00             4         6             2         2   \n",
      "2021-08-01 01:00:00             7         7             2         7   \n",
      "\n",
      "                     direction_35  count_35  \n",
      "detected                                     \n",
      "2021-08-01 00:00:00            30        42  \n",
      "2021-08-01 01:00:00            13        21  \n",
      "\n",
      "[2 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "df_loc = pd.read_csv('../all_counter_locations.csv')\n",
    "df_loc.info()\n",
    "print()\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposição sazonal (MSTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposição sazonal (STL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serie original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df.resample('D').sum()\n",
    "\n",
    "location_ids = [12, 13]\n",
    "contadores = [f\"count_{loc}\" for loc in location_ids]\n",
    "\n",
    "for contador in contadores:\n",
    "    if contador in df_daily.columns:\n",
    "        series = df_daily[contador]\n",
    "        \n",
    "        # Substituir zeros para evitar problemas no log\n",
    "        series = series.replace(0, np.nan).fillna(method='ffill')  \n",
    "\n",
    "        series_log = np.log1p(series)  # Usa log(1 + x) para evitar -inf\n",
    "        \n",
    "        stl = STL(series_log, period=7, robust=True)\n",
    "        res = stl.fit()\n",
    "\n",
    "        print(f\"Resultados para {contador}:\")\n",
    "        print(res.seasonal.head())\n",
    "\n",
    "        fig = res.plot()\n",
    "        fig.set_size_inches((20, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df.resample('D').sum()\n",
    "\n",
    "location_ids = [12, 13] \n",
    "\n",
    "# Gera os nomes das colunas com base nos location_ids escolhidos\n",
    "contadores = [f\"count_{loc}\" for loc in location_ids]\n",
    "\n",
    "# Loop para aplicar STL aos contadores selecionados\n",
    "for contador in contadores:\n",
    "    if contador in df_daily.columns:  # Verifica se a coluna existe\n",
    "        series = df_daily[contador]\n",
    "\n",
    "        # Aplica STL com sazonalidade semanal (7 dias)\n",
    "        stl = STL(series, period=7, robust=True, seasonal_deg=0, trend_deg=0, low_pass_deg=0)\n",
    "        res = stl.fit()\n",
    "\n",
    "        # Exibe os primeiros valores da decomposição sazonal\n",
    "        print(f\"Resultados para {contador}:\")\n",
    "        print(res.seasonal.head())\n",
    "\n",
    "        fig = res.plot()\n",
    "        fig.set_size_inches((20, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por estação do Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverno\n",
    "\n",
    "location_id = 12  \n",
    "\n",
    "# localização\n",
    "location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0]\n",
    "# Filtra apenas os dados do inverno\n",
    "df_winter = df[((df.index.month == 12) & (df.index.day >= 21)) | \n",
    "               (df.index.month == 1) | \n",
    "               (df.index.month == 2) | \n",
    "               ((df.index.month == 3) & (df.index.day <= 19))]\n",
    "\n",
    "# Agrega os dados por dia\n",
    "contador = f\"count_{location_id}\"\n",
    "series_winter = df_winter.resample('D').sum()[contador]\n",
    "\n",
    "# Remove períodos com zero ou NaN\n",
    "series_winter = series_winter.loc[series_winter > 0].dropna()\n",
    "\n",
    "# decomposição sazonal com período semanal (7 dias)\n",
    "stl = STL(series, period=7, robust=True, seasonal_deg=0, trend_deg=0, low_pass_deg=0)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.set_size_inches(20, 8)\n",
    "plt.suptitle(f'{location_name} - Winter', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sazonalidade semanal: Podemos identificar um padrões semanal ao longo dos 3 invernos. O uso varia consistentemente ao longo da semana. Parece que há um aumento no fim do inverno (pode ser ao aumento das temperaturas)\n",
    "- Résiduos: Os résiduos tem de ser aléatorios e dispersos ao redor do zéro, para que haja uma boa decomposição (os résiduos não podem ter um padrão). Pontos muitos afastados indicam um evento atípico. como chuva ou um evento na cidada (fériado, concerto, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média de cicilistas para cada dia da semana ao longos dos 3 inverno \n",
    "\n",
    "# Adicionar uma coluna com o dia da semana (0 = segunda-feira, 6 = domingo)\n",
    "df_winter['weekday'] = df_winter.index.weekday  \n",
    "\n",
    "# Calcular a média de ciclistas por dia da semana\n",
    "mean_by_weekday = df_winter.groupby('weekday')[contador].mean()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(mean_by_weekday.index, mean_by_weekday.values, tick_label=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Average Cyclist Count\")\n",
    "plt.title(\"Average Cyclist Count per Day of the Week (Winter)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar os pontos muito afastados para tentar percebe-los\n",
    "# Definir um limite para outliers (ex: 3 desvios padrão dos resíduos)\n",
    "limite_superior = res.resid.mean() + 3 * res.resid.std()\n",
    "limite_inferior = res.resid.mean() - 3 * res.resid.std()\n",
    "\n",
    "# Filtrar os dias que são outliers\n",
    "outliers = res.resid[(res.resid > limite_superior) | (res.resid < limite_inferior)]\n",
    "\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2021-12-26   -631.318748 --> Logo após ao Natal, cansaço das festas?\n",
    "- 2022-03-19    849.891908 --> Dia do Pai. Mais passeios em família. Sendo que é um sábado, tinhamos visto que há mais utilização ao fim de semana. \n",
    "- 2023-01-15    568.632678 --> Domingo, podera ter estado bom tempo. (acima da média)\n",
    "- 2023-02-21    561.573221 --> Carnaval (terça-feira)\n",
    "- 2023-03-05   -551.764488 --> Domingo, mas houve uma queda da temperatura \n",
    "- 2023-03-19    701.932245 --> Dia do Pai (Domingo)\n",
    "- 2024-02-11   -597.327963 --> Domingo, mas pode ter havido um fator climatico que pode ter influenciado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primavera \n",
    "\n",
    "location_id = 12  \n",
    "location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0]\n",
    "df_spring = df[(df.index.month == 3) & (df.index.day >= 20) |\n",
    "               (df.index.month == 4) |\n",
    "               (df.index.month == 5) |\n",
    "               (df.index.month == 6) & (df.index.day <= 20)]\n",
    "\n",
    "# Agrega os dados por dia\n",
    "contador = f\"count_{location_id}\"\n",
    "series_spring = df_spring.resample('D').sum()[contador]\n",
    "\n",
    "# Remove períodos com zero ou NaN\n",
    "series_spring = series_spring.loc[series_spring > 0].dropna()\n",
    "\n",
    "# decomposição sazonal com período semanal (7 dias)\n",
    "stl = STL(series_spring, period=7, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.set_size_inches(20, 8)\n",
    "plt.suptitle(f'{location_name} - Spring', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparação entre a primavera e o inverno: Podemos ver que há maior utilização no inverno de 2022 que na primavera, mas que depois os outros invernos já tem menos utilização. Será que foi um inverno mais quente?\n",
    "- No geral temos um aumento da utilização das bicicletas e continuas a ver um padrão semanal. Provavelmente os fins de semanas ainda são os dias com mais uso. No geral, podemos ver que há um aumento gradual ao longo da estação. Os picos negativos são menos acentuados, o que indica que há mais utilização. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar os pontos muito afastados para tentar percebe-los\n",
    "# Definir um limite para outliers (ex: 3 desvios padrão dos resíduos)\n",
    "limite_superior = res.resid.mean() + 3 * res.resid.std()\n",
    "limite_inferior = res.resid.mean() - 3 * res.resid.std()\n",
    "\n",
    "# Filtrar os dias que são outliers\n",
    "outliers = res.resid[(res.resid > limite_superior) | (res.resid < limite_inferior)]\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2022-04-09   -556.624537 --> Não há um evento especifico, pode ser alteração climatica. \n",
    "- 2022-04-15    701.595524 --> Férias escolares e fériado, que pode gerar um aumento \n",
    "- 2022-04-22   -556.497495 --> Descida da temperatura\n",
    "- 2022-04-25    629.944133 --> Fériado importante em Portugal que geralmente aumenta a atividade. \n",
    "- 2023-04-21   -592.331533 --> Alterações no clima?\n",
    "- 2023-05-01    578.035037 --> Fériado, dia do trabalhador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verão\n",
    "\n",
    "location_id = 12  \n",
    "location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0]\n",
    "df_summer = df[(df.index.month == 6) & (df.index.day >= 21) |\n",
    "               (df.index.month == 7) |\n",
    "               (df.index.month == 8) |\n",
    "               (df.index.month == 9) & (df.index.day <= 22)]\n",
    "\n",
    "# Agrega os dados por dia\n",
    "contador = f\"count_{location_id}\"\n",
    "series_summer = df_summer.resample('D').sum()[contador]\n",
    "\n",
    "# Remove períodos com zero ou NaN \n",
    "series_summer = series_summer.loc[series_summer > 0].dropna()\n",
    "\n",
    "# decomposição sazonal com período semanal (7 dias)\n",
    "stl = STL(series_summer, period=7, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.set_size_inches(20, 8)\n",
    "plt.suptitle(f'{location_name} - Summer', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparação entre a primavera e o verão: No geral a utilização de bicicletas é ligeiramente maior no verão que na primavera. \n",
    "- Sazonalidade semanal: Podemos identificar um padrão semanal, com utilização maior ao fim de semana.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar os pontos muito afastados para tentar percebe-los\n",
    "# Definir um limite para outliers (ex: 3 desvios padrão dos resíduos, porque cerca de 99% dos dados caem dentro de 3 desvios padrões da média)\n",
    "limite_superior = res.resid.mean() + 3 * res.resid.std()\n",
    "limite_inferior = res.resid.mean() - 3 * res.resid.std()\n",
    "\n",
    "# Filtrar os dias que são outliers\n",
    "outliers = res.resid[(res.resid > limite_superior) | (res.resid < limite_inferior)]\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2021-09-18    549.783361 + 2021-09-19    511.723923 (Sabado e domingo) --> ArcoLisboa: Feira de arte contemporânea. Evento que atrai muitas pessoas a Lisboa. \n",
    "- 2022-08-08   -910.784309 --> Segunda. Chuva?\n",
    "- 2022-08-19   -559.907713 --> Depressão térmica, vento forte\n",
    "- 2022-09-12   -616.726351 --> Chuva e trovoada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outono\n",
    "\n",
    "location_id = 12  \n",
    "location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0]\n",
    "df_autumn = df[(df.index.month == 9) & (df.index.day >= 23) |\n",
    "               (df.index.month == 10) |\n",
    "               (df.index.month == 11) |\n",
    "               (df.index.month == 12) & (df.index.day <= 20)]\n",
    "\n",
    "# Agrega os dados por dia\n",
    "contador = f\"count_{location_id}\"\n",
    "series_autumn = df_autumn.resample('D').sum()[contador]\n",
    "\n",
    "# Remove períodos com zero ou NaN\n",
    "series_autumn = series_autumn.loc[series_autumn > 0].dropna()\n",
    "\n",
    "# decomposição sazonal com período semanal (7 dias)\n",
    "stl = STL(series_autumn, period=7, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.set_size_inches(20, 8)\n",
    "plt.suptitle(f'{location_name} - Autumn', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparação entre o verão e o outuno: No geral a utilização de bicicletas é menor que no verão e provavelmente também na primavera. \n",
    "- Sazonalidade semanal: Podemos identificar um padrão semanal, com utilização maior ao fim de semana.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar os pontos muito afastados para tentar percebe-los\n",
    "# Definir um limite para outliers (ex: 3 desvios padrão dos resíduos, porque cerca de 99% dos dados caem dentro de 3 desvios padrões da média)\n",
    "limite_superior = res.resid.mean() + 3 * res.resid.std()\n",
    "limite_inferior = res.resid.mean() - 3 * res.resid.std()\n",
    "\n",
    "# Filtrar os dias que são outliers\n",
    "outliers = res.resid[(res.resid > limite_superior) | (res.resid < limite_inferior)]\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2021-10-05    651.120365 --> Fériado (terça)\n",
    "- 2021-10-30   -638.344398 --> sábado: Percipitação muito frote \n",
    "- 2021-10-31   -753.633627 --> Domingo: Percipitação muito frote \n",
    "- 2022-09-25    718.489451 --> Domingo\n",
    "- 2022-11-01    632.873767 --> Terça, Fériado\n",
    "- 2023-09-24    711.241277 --> Domingo com temperaturas de 20º\n",
    "- 2023-10-01    958.663631 --> Domingo, temperaturas altas, acima da média\n",
    "- 2023-10-19   -777.355366 --> Quinta, depressão BABET e ALINE, com muita chuva e rajadas de vento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por dias da semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_ids = [12] \n",
    "# Loop para aplicar STL aos contadores selecionados\n",
    "for location_id in location_ids:\n",
    "\n",
    "    if contador in df_daily.columns:\n",
    "        location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0] \n",
    "        series = df_daily[contador]\n",
    "\n",
    "        weekdays = series[series.index.weekday < 5]  #(segunda a sexta-feira)\n",
    "\n",
    "        # Função para aplicar STL e gerar gráfico\n",
    "        def apply_stl_and_plot(data, title):\n",
    "            stl = STL(data, period=7, robust=True)\n",
    "            res = stl.fit()\n",
    "\n",
    "            # Exibe os primeiros valores da decomposição sazonal\n",
    "            print(f\"Results {title}:\")\n",
    "            print(res.seasonal.head())\n",
    "\n",
    "            # Grafico\n",
    "            fig = res.plot()\n",
    "            fig.set_size_inches((20, 8))\n",
    "            plt.suptitle(title, fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Aplica STL para os dias úteis\n",
    "        print(f\"{location_name}\")\n",
    "        apply_stl_and_plot(weekdays, f\"{location_name} - week days\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por fim de semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_ids = [12] \n",
    "# Loop para aplicar STL aos contadores selecionados\n",
    "for location_id in location_ids:\n",
    "\n",
    "    if contador in df_daily.columns:\n",
    "        location_name = df_loc[df_loc['locationId'] == location_id]['name'].iloc[0] \n",
    "        series = df_daily[contador]\n",
    "\n",
    "        weekends = series[series.index.weekday >= 5] \n",
    "\n",
    "        # Função para aplicar STL e gerar gráfico\n",
    "        def apply_stl_and_plot(data, title):\n",
    "            stl = STL(data, period=7, robust=True)\n",
    "            res = stl.fit()\n",
    "\n",
    "            # Exibe os primeiros valores da decomposição sazonal\n",
    "            print(f\"Results {title}:\")\n",
    "            print(res.seasonal.head())\n",
    "\n",
    "            # Grafico\n",
    "            fig = res.plot()\n",
    "            fig.set_size_inches((20, 8))\n",
    "            plt.suptitle(title, fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Aplica STL para os fins de semana\n",
    "        print(f\"{location_name}\")\n",
    "        apply_stl_and_plot(weekends, f\"{location_name} - weekend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
